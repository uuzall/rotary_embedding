{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import matplotlib.pyplot as plt \n",
    "import einops \n",
    "from tqdm import trange \n",
    "import wandb \n",
    "\n",
    "import rotary_embedding\n",
    "import gpt \n",
    "import data \n",
    "\n",
    "device = 'cuda' if torch.has_cuda else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, encode = data._init_data() \n",
    "config = gpt.ModelArgs() \n",
    "lr, bs = config.lr, config.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.482137 M parameters.\n"
     ]
    }
   ],
   "source": [
    "model = gpt.gpt_model(vocab_size=vocab_size).to(device) \n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "2023-09-09 10:12:36.555083: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-09 10:12:37.695698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33muuzall\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dbf1507a924ff3a50654816bae0146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016667934200086165, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/sda1/Programming/rotary_embedding/wandb/run-20230909_101240-fjz6oohl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uuzall/Rotary%20Embedding/runs/fjz6oohl' target=\"_blank\">GPT with max trainable rotary emb dim</a></strong> to <a href='https://wandb.ai/uuzall/Rotary%20Embedding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uuzall/Rotary%20Embedding' target=\"_blank\">https://wandb.ai/uuzall/Rotary%20Embedding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uuzall/Rotary%20Embedding/runs/fjz6oohl' target=\"_blank\">https://wandb.ai/uuzall/Rotary%20Embedding/runs/fjz6oohl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_name = 'GPT with max trainable rotary emb dim' \n",
    "\n",
    "wandb.init(\n",
    "    project='Rotary Embedding', \n",
    "    entity='uuzall', \n",
    "    sync_tensorboard=True, \n",
    "    name=project_name, \n",
    ")\n",
    "\n",
    "writer = torch.utils.tensorboard.SummaryWriter(f'runs/{project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 10:12:42.742867: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-09 10:12:42.787399: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-09 10:12:42.788900: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]2023-09-09 10:12:44.011381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Iterations: 10000/10000: 100%|██████████| 10000/10000 [1:35:17<00:00,  1.75it/s, best_iter=6144, best_val_loss=0.974, loss=0.736, val_loss=1]    \n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "losses, val_losses, val_loss, best_val_loss, best_val_iter = list(), list(), 0, 100, 0\n",
    "\n",
    "max_iters = 10000\n",
    "global_step = 0 \n",
    "for iter in (loop := trange(max_iters)): \n",
    "\tx, y = data.dataloader('train')\n",
    "\t\n",
    "\tlogits = model(x.to(device))\n",
    "\n",
    "\tB, T, C = logits.shape \n",
    "\tlogits = logits.view(B*T, C)\n",
    "\ttargets = y.view(B*T)\n",
    "\tloss = F.cross_entropy(logits, targets.to(device))\n",
    "\twriter.add_scalar('train_losses/loss', loss.item(), global_step)\n",
    "\tloss.backward()\n",
    "\toptimizer.step() \n",
    "\tmodel.zero_grad()\n",
    "\n",
    "\tif iter % 512 == 0: \n",
    "\t\tloss_dim = 100\n",
    "\t\tval_loss_tensor = torch.zeros((loss_dim))\n",
    "\t\tfor j in range(loss_dim): \n",
    "\t\t\tx, y = data.dataloader('val')\n",
    "\t\t\twith torch.no_grad(): \n",
    "\t\t\t\tlogits = model(x.to(device))\n",
    "\n",
    "\t\t\t\tB, T, C = logits.shape \n",
    "\t\t\t\tlogits = logits.view(B*T, C)\n",
    "\t\t\t\ttargets = y.view(B*T)\n",
    "\t\t\t\tval_loss = F.cross_entropy(logits, targets.to(device)) \n",
    "\t\t\tval_loss_tensor[j] = val_loss.item()\n",
    "\t\tval_loss = val_loss_tensor.mean().item()\n",
    "\t\twriter.add_scalar('test_losses/loss', val_loss, global_step)\n",
    "\t\tif val_loss < best_val_loss: \n",
    "\t\t\tbest_val_loss = val_loss\n",
    "\t\t\tbest_val_iter = iter\n",
    "\t\t\ttorch.save(model.state_dict(), f'models/gpt_best_performing.pth')\n",
    "\n",
    "\tloop.set_description(f'Iterations: {iter+1}/{max_iters}')\n",
    "\tloop.set_postfix(loss=loss.item(), val_loss=val_loss, best_val_loss=best_val_loss, best_iter=best_val_iter)\n",
    "\tglobal_step += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Best performing: 0.995 (iteration 7000) Dim: 32\n",
    "2. Best Performing: 0.973 (iteration 6000) Dim: max (192)\n",
    "3. Best Performing: 0.974 (iteration 6144) Dim: max + trainable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
